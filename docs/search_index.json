[
["index.html", "Curso de R 1 Introducción", " Curso de R Juan R González 2020-11-03 1 Introducción Este bookdown sirven como notas para el curso Análisis descriptivo y estadística básica en estudios biomédicos con R y Rmarkdown impartido en el Insituto Aragonés de Ciencias de la Salud El contenido del curso tiene los siguientes temas: Modulo I: El entorno R y estadística descriptiva Tema 1: Introducción a R - Rstudio (2 horas) Inicio R: instalando R y Rstudio Lectura de datos en R Tema 2: Análisis descriptivo Modulo II: Inferencia estadística y modelos Tema 3: Análisis inferencial Contrastes de hipótesis Tests paramétricos: t-test, ANOVA, Chi-cuadrado Tests no paramétricos: Wilcoxon, Kruskall-Wallis, Fisher Tema 4: Modelos de regresión Regresión lineal Regresión logística Módulo III: Visualización Tema 5: Tablas y Gráficos Funciones Básicas de R Lattice ggplot2 Módulo IV: Investigación reproducible Tema 6: Knitr Tema 7: R Mardown Tema 8: Creación de reportes estadísticos usando librerías R Este material está licenciado bajo una Creative Commons Attribution 4.0 International License. "],
["importar.html", "2 Importar datos a R 2.1 Directorio de trabajo 2.2 Importar datos de texto", " 2 Importar datos a R Rstudio posee una pestaña en el Entorno (panel derecho-arriba, recordad la primera lección) y un botón que nos permite importar datasets de distintos formatos (ver figura). Esta es una forma sencilla de importar datos, pero siempre es recomendable importar archivos usando código (scripts) que nos permite compartir flujos de trabajo y análisis entre investigadores. En ese botón vemos que podemos importar datos de distintos tipos Importar archivos Fijémosnos que los dos primeros menus hablan de importar ficheros de texto. También podemos importar ficheros de Excel, y de otros softwares como SPSS, SAS o Stata. Los ejemplos para este curso (y en general se suele hacer así) utilizará datos en formato texto. En este formato disponemos de las variables en columnas y los individuos o unidades de análisis en filas. NOTA: Si se dispone de datos en formato Excel o SPSS se pueden exportar de forma sencilla a texto. Este formato es muy útil ya que estamos acostumbrados a visualizar datos en formato tabular; es decir, como una tabla. Podemos pensar que dependiendo de como se separen las observaciones tenemos distintos tipos de datos tabulares, pero en realidad su estructura es similar: variables en columnas y las observaciones de un individuo separadas por una marca o carácter. Este carácter puede ser un espacio, un tabulador, una coma, punto y coma etc… El formato tabular mas extendido es el CSV, donde las observaciones están separadas por comas, pero en este curso usaremos datos en formato texto separados por tabuladores que también es un formato muy extendido (TSV). 2.1 Directorio de trabajo Para las clases y los ejercicios usaremos varios conjuntos de datos que disponemos en varios ficheros que pueden bajarse de la carpeta XXX del Moodle de la asignatura. Se recomienda crear un proyecto y crear una carpeta “datos” donde poner estos datasets que vamos a usar de ejemplo (ver video). Si no queréis trabajar con proyectos, recordemos que tneéis que cambiar el directorio de trabajo allí donde hayáis bajado los datos de Moodle. Recordad que esto lo podéis hacer con el menu de Rstudio Archivo de trabajo O bien (recomendado) podéis hacerlo escribiendo una instrucción en el script. Como yo tengo la carpeta “datos” en el directorio C:/Juan/cursos/R_Zaragoza/material_curso_online) escribiría: setwd(&quot;C:/Juan/cursos/R_Zaragoza/material_curso_online&quot;) 2.2 Importar datos de texto Una vez tenemos el directorio de trabajo establecido ilustraremos como importar, por ejemplo, el fichero de datos “multicentric.txt” que recoge información sobre un estudio multicéntrico de casos y controles para estudiar factores pronóstico del cáncer de cervix. Estos serían los pasos que tendríamos que llevar a cabo Indicamos que queremos importar unos datos En el navegador que se abre buscamos la carpeta “datos” y seleccionamos el archivo “multicentric.txt” [NOTA: si no hemos hecho bien el proyecto o cambiado el directorio de trabajo, podemos navegar hasta buscar la carpeta donde hayamos bajado los datos]. A continuación nos aparecerá este cuadro Abajo a la derecha se puede ver cómo nos quedarán nuestros datos cuando se importen. Fijémonos que el nombre de las variables que estaban en la primera fila, no se han importado correctamente y que R ha puesto como nombre de las variables V1, V2, V3, …. Esto ocurre porque por defecto (parte izquierda) la opción “heading” es “No”. Debemos cambiarlo a “Yes” cuando tengamos datos con los nombres de las variables en la primera fila (esto es lo habitual). Si los datos de texto estuvieran separados por otra cosa que no fuesen tabuladores, no veríamos columnas. En ese caso debems cambiar el delimitador usando la opción “Separator”. Cuando hacemos click sobre el botón “Import” los datos se cargan como un objeto de R que se llama “multicentric”. Este nombre se puede cambiar en la caja “Name” que hay arriba a la izquierda. A parte de que se carge el dataset como un objeto de R, también se abren los datos como si fuese SPSS: Ahora, una vez hemos cargado nuestros datos, podemos abrir un script de R y empezar a hacer análisis con ellos. Ahora podéis abrir un script nuevo y empezar a escribir y ejecutar las instrucciones que se detallan a continuación. Recordemos que se puede hacer mediante el menu File &gt; New File &gt; R Script. Un script, podría quedar entonces de la siguiente manera tras pedir que R importe los datos multicentric.txt Lo primero que vemos es que tras el simbolo # el texto está en verde. Eso indica que esa parte no es código de R y no se ejecutará. Esto es recomendable para ir indicando qué hacen los siguientes comandos (compartir código entre investigadores). Las instrucciones que vemos en el script y que se repiten abajo, también sirven para importar datos utilizando comandos de R y no el menú como hemos visto anteriormente. Primero cambio el directorio de trabajo (si no estoy donde tengo la carpeta de datos es necesario) # Cambio el directorio de trabajo setwd(&quot;C:/Juan/cursos/R_Zaragoza/material_curso_online&quot;) y luego cargo los datos # Importo los datos multicentric &lt;- read.delim(&quot;datos/multicentric.txt&quot;) "],
["manejo-de-datos.html", "3 Manejo de datos 3.1 Visualización de datos 3.2 Creación de variables 3.3 Recodificación de variables 3.4 Filtrado de datos", " 3 Manejo de datos Una vez importados los datos, ya podemos empezar con nuestros análisis estadísticos. Pero antes, mostraremos cómo crear nuevas variables ya que a menudo, antes de empezar con los análisis necesitamos crear o recodificar nuevas variables que contengan la información que queremos tratar. Seguiremos usando los datos guardados en el fichero multicentric.txt que están cargados en un objeto llamado multicentric. La idea es que en el script que habéis abierto, podéis ir escribiendo estos comandos de R y ver por la consola qué resultados obtenéis. Recordad que cuando escribáis la instrucción, la podéis ejecutar con el boton “Run” que tenéis arriba a la derecha en la ventana del scipt o bien situando el cursor en la linea de comando y clickando “Crtl + R”. En este material, el primer recuadro en gris corresponde al comando que tenéis que escribir en el script (ventana superior-izquierda de RStudio) y el siguiente recuadro en gris muestra lo que veríais por la línea de comandos (ventana inferior-izquierda de R studio) 3.1 Visualización de datos Empezemos viendo qué datos tenemos. Para ello usaremos la función head() head(multicentric) ident pais status edad niveledu fumar edad1sex regcompa totcompa ets 1 10001 Brasil Control 64 primaria ex-fumador 16 2 2-3 si 2 10002 Brasil Caso 51 primaria fumador 17 1 1 si 3 10003 Brasil Control 48 ninguno fumador 14 2 2-3 no 4 10004 Brasil Caso 49 ninguno no fumador 23 1 1 no 5 10005 Brasil Control 41 primaria no fumador 23 1 1 no 6 10006 Brasil Caso 45 primaria fumador 18 1 1 no co edinico edfinco durco condon embara edademba nembara pap edad1pap 1 no NA NA NA no si 16 9 si 40 2 no NA NA NA no si 17 13 si 45 3 no NA NA NA no si 14 11 no NA 4 no NA NA NA no si 23 13 no NA 5 no NA NA NA no si 24 3 si 30 6 si 22 38 14 no si 18 5 si 33 vph 1 negativo 2 positivo 3 positivo 4 positivo 5 negativo 6 positivo Para saber cuántos individuos y cuántas variables tenemos en nuestra base de datos podemos usar la función dim(). nrow() nos daría el número de individuos y ncol() el número de variables dim(multicentric) [1] 2910 21 nrow(multicentric) [1] 2910 ncol(multicentric) [1] 21 También podemos ver qué tipo de variables tenemos y cuáles son sus categorías str(multicentric) &#39;data.frame&#39;: 2910 obs. of 21 variables: $ ident : int 10001 10002 10003 10004 10005 10006 10007 10008 10009 10010 ... $ pais : chr &quot;Brasil&quot; &quot;Brasil&quot; &quot;Brasil&quot; &quot;Brasil&quot; ... $ status : chr &quot;Control&quot; &quot;Caso&quot; &quot;Control&quot; &quot;Caso&quot; ... $ edad : int 64 51 48 49 41 45 51 42 58 76 ... $ niveledu: chr &quot;primaria&quot; &quot;primaria&quot; &quot;ninguno&quot; &quot;ninguno&quot; ... $ fumar : chr &quot;ex-fumador&quot; &quot;fumador&quot; &quot;fumador&quot; &quot;no fumador&quot; ... $ edad1sex: int 16 17 14 23 23 18 29 19 22 27 ... $ regcompa: int 2 1 2 1 1 1 1 2 1 1 ... $ totcompa: chr &quot;2-3&quot; &quot;1&quot; &quot;2-3&quot; &quot;1&quot; ... $ ets : chr &quot;si&quot; &quot;si&quot; &quot;no&quot; &quot;no&quot; ... $ co : chr &quot;no&quot; &quot;no&quot; &quot;no&quot; &quot;no&quot; ... $ edinico : int NA NA NA NA NA 22 30 32 NA NA ... $ edfinco : int NA NA NA NA NA 38 38 32 NA NA ... $ durco : int NA NA NA NA NA 14 8 1 NA NA ... $ condon : chr &quot;no&quot; &quot;no&quot; &quot;no&quot; &quot;no&quot; ... $ embara : chr &quot;si&quot; &quot;si&quot; &quot;si&quot; &quot;si&quot; ... $ edademba: int 16 17 14 23 24 18 29 20 22 30 ... $ nembara : int 9 13 11 13 3 5 1 7 8 2 ... $ pap : chr &quot;si&quot; &quot;si&quot; &quot;no&quot; &quot;no&quot; ... $ edad1pap: int 40 45 NA NA 30 33 45 NA 42 38 ... $ vph : chr &quot;negativo&quot; &quot;positivo&quot; &quot;positivo&quot; &quot;positivo&quot; ... Finalmente, si queremos saber el nombre de las variables que tenemos en nuestra base de datos usaríamos: colnames(multicentric) [1] &quot;ident&quot; &quot;pais&quot; &quot;status&quot; &quot;edad&quot; &quot;niveledu&quot; &quot;fumar&quot; &quot;edad1sex&quot; &quot;regcompa&quot; [9] &quot;totcompa&quot; &quot;ets&quot; &quot;co&quot; &quot;edinico&quot; &quot;edfinco&quot; &quot;durco&quot; &quot;condon&quot; &quot;embara&quot; [17] &quot;edademba&quot; &quot;nembara&quot; &quot;pap&quot; &quot;edad1pap&quot; &quot;vph&quot; Antes de explicar cómo crear nuevas variables, veamos algunos aspectos básicos de R en cuanto al acceso de las variables. Supongamos que queremos calcular cualquier estadístico descriptivo de alguna de las variables o ver un resumen de ella. Para esta tarea podemos utilizar distintas funciones de R que normalmente se ejecutan como funcion(). Dentro del paréntesis debemos indicarle cuál es la variable que queremos analizar. Para ello, utilizaremos el símbolo $ [también podría usarse [[ ]] pero intentaremos evitar escribir demasiado código]. Así, por ejemplo, si queremos calcular la media de la primera relación sexual (variable edad1sex) bastaría con ejecutar mean(multicentric$edad1sex, na.rm=TRUE) [1] 19.72932 NOTA: na.rm=TRUE debe escribirse porque si no, R devuelve NA cuando hay missings en una variable. Con esta opción se analizan casos completos. También es interesante conocer estas otras funciones. Descriptiva de una variable categórica. Ejemplo: cuantas mujeres hay de cada país table(multicentric$pais) Brasil Colombia Espaia Filipinas Marruecos Peri Tailandia 347 323 376 636 332 312 584 Descriptiva de una variable continua. Ejemplo: edad de las participantes summary(multicentric$edad) Min. 1st Qu. Median Mean 3rd Qu. Max. 20.00 40.00 49.00 48.86 58.00 84.00 Uno de los aspectos que más cuestan al principio de usar R es familiarizarse con la escritura de código. Rstudio nos ayuda puesto que podemos autocompletar el nombre de una base de datos o de una función. Por ejemplo, basta con empezar a escribir “multi” y dar al tabulador para que en el script se autocomplete la palabra “multicentric”. Una vez escrito el nombre de la base de datos, si escribimos el símbolo $ obtenemos un desplegable que nos muestra todas las variables que hay en ese objeto y basta con seleccionar la variable que queremos resumir para que R la ponga directamente en el script tal y como muestra la siguiente figura. También podemos acceder a una variablae usando [ e indicando el número de columna donde está la variable que queremos resumir o su nombre. En este caso como edad1sex está en la columna 7 escribiríamos mean(multicentric[ , 7], na.rm=TRUE) [1] 19.72932 o usando su nombre mean(multicentric[ , &quot;edad1sex&quot;], na.rm=TRUE) [1] 19.72932 pero como se ha indicado anteriormente, lo más sencillo es usar $ ya que ayuda a evitar errores en la escritura que es uno de los principales problemas para principiantes. 3.2 Creación de variables Para crear una nueva variable, por ejemplo la edad de la primera relación sexual menos 18, tendríamos que escribir multicentric$edad1sex2 &lt;- multicentric$edad1sex - 18 Donde a la izquierda de &lt;- se pone el nombre de la nueva variable que queremos añadir a multicentric (por eso se pone el $) y a la derecha la operación que queremos hacer. NOTA: el símbolo &lt;- es como un = pero este último se usa para los argumentos de una función (lo veremos más adelante). Esta forma de escribir es muy larga y complicada, sobre todo para los nuevos usuarios de R, y puede introducir errores fácilmente. Es por ello que podemos trabajar con una serie de librerías que facilitan llevar a cabo estas operaciones. Estas liberías forman parte de los desarrolladores de RStudio y son un compendio de funciones para el análisis científico de datos (Data Science). Si queremos usar estas funciones, debemos instalar las librerías de tydiverse [https://www.tidyverse.org/] ejecutando: install.packages(tidyverse) Después debemos cargar estas librerías con library(tidyverse) Ahora, para crear una nueva variable basta con usar la función mutate() que tiene el primer argumento el nombre de nuestra base datos y luego la fórmula que queremos aplicar para calcular la nueva variable. Nos fijamos que ya no es necesario el uso de $ y la instrucción se lee de forma más intuitiva. multicentric &lt;- mutate(multicentric, edad1sex2 = edad1sex - 18) Si ahora damos un vistazo a las variables que hay en multicentric veremos que al final se ha añadido una nueva variable (edad1sex2) que es la que hemos creado str(multicentric) &#39;data.frame&#39;: 2910 obs. of 22 variables: $ ident : int 10001 10002 10003 10004 10005 10006 10007 10008 10009 10010 ... $ pais : chr &quot;Brasil&quot; &quot;Brasil&quot; &quot;Brasil&quot; &quot;Brasil&quot; ... $ status : chr &quot;Control&quot; &quot;Caso&quot; &quot;Control&quot; &quot;Caso&quot; ... $ edad : int 64 51 48 49 41 45 51 42 58 76 ... $ niveledu : chr &quot;primaria&quot; &quot;primaria&quot; &quot;ninguno&quot; &quot;ninguno&quot; ... $ fumar : chr &quot;ex-fumador&quot; &quot;fumador&quot; &quot;fumador&quot; &quot;no fumador&quot; ... $ edad1sex : int 16 17 14 23 23 18 29 19 22 27 ... $ regcompa : int 2 1 2 1 1 1 1 2 1 1 ... $ totcompa : chr &quot;2-3&quot; &quot;1&quot; &quot;2-3&quot; &quot;1&quot; ... $ ets : chr &quot;si&quot; &quot;si&quot; &quot;no&quot; &quot;no&quot; ... $ co : chr &quot;no&quot; &quot;no&quot; &quot;no&quot; &quot;no&quot; ... $ edinico : int NA NA NA NA NA 22 30 32 NA NA ... $ edfinco : int NA NA NA NA NA 38 38 32 NA NA ... $ durco : int NA NA NA NA NA 14 8 1 NA NA ... $ condon : chr &quot;no&quot; &quot;no&quot; &quot;no&quot; &quot;no&quot; ... $ embara : chr &quot;si&quot; &quot;si&quot; &quot;si&quot; &quot;si&quot; ... $ edademba : int 16 17 14 23 24 18 29 20 22 30 ... $ nembara : int 9 13 11 13 3 5 1 7 8 2 ... $ pap : chr &quot;si&quot; &quot;si&quot; &quot;no&quot; &quot;no&quot; ... $ edad1pap : int 40 45 NA NA 30 33 45 NA 42 38 ... $ vph : chr &quot;negativo&quot; &quot;positivo&quot; &quot;positivo&quot; &quot;positivo&quot; ... $ edad1sex2: num -2 -1 -4 5 5 0 11 1 4 9 ... 3.3 Recodificación de variables En biomedicina a veces interesa recodificar nuevas variables según varios criterios. Veamos algunos ejemplos Recodificar una variable continua en una categórica que toma valores superiores o inferiores a un valor. Ejemplo: edad de primera relación sexual antes o despues de 18 años multicentric &lt;- mutate(multicentric, edad1sex3 = ifelse(edad1sex &lt;=18, 0 , 1)) table(multicentric$edad1sex3) 0 1 1379 1510 Recodificar una variable continua en cuartiles. Ejemplo: edad de primera relación sexual en cuartiles multicentric &lt;- mutate(multicentric, edad1sex4 = cut(edad1sex, quantile(edad1sex, na.rm=TRUE))) table(multicentric$edad1sex4) (5,16] (16,19] (19,22] (22,52] 736 872 596 684 Recodificar una variable según unos puntos de corte y ponerles una etiqueta. Ejemplo: edad de primera relación sexual antes de los 14, entre los 15 y 18 (ambos incluidos) y más de los 18 (19 o más) multicentric &lt;- mutate(multicentric, edad1sex5 = cut(edad1sex, c(-Inf, 14, 18, Inf), labels=c(&quot;&lt;14&quot;, &quot;15-18&quot;, &quot;19+&quot;))) table(multicentric$edad1sex5) &lt;14 15-18 19+ 257 1122 1510 Recodificar una variable con ciertas categorías en otras. Ejemplo: no-fumadoras y ex-fumadoras en una categoría ‘No’ y fumadoras en ‘Si’ multicentric &lt;- mutate(multicentric, fumarNewCat = recode(fumar, &quot;no fumador&quot; = &quot;No&quot;, &quot;ex-fumador&quot; = &quot;No&quot;, &quot;fumador&quot; = &quot;Si&quot;)) table(multicentric$fumar) ex-fumador fumador no fumador 223 292 2395 table(multicentric$fumarNewCat) No Si 2618 292 3.4 Filtrado de datos También podemos filtrar una base de datos para hacer unos análisis específicos en un subgrupo de individuos. Supongamos que queremos describir nuestros controles. Para ello utilizaremos la función filter(). Sabemos que el estado Caso/Control se encuentra en la variable status por eso escribimos controles &lt;- filter(multicentric, status==&quot;Control&quot;) dim(controles) [1] 1421 26 Usamos == para poner una condición de igualdad. Para otras condiciones deberemos usar Por ejemplo, si queremos seleccionar a los casos que hayan tenido una infección por VPH (variable vph) deberíamos escribir casos.vph &lt;- filter(multicentric, status==&quot;Caso&quot; &amp; vph==&quot;positivo&quot;) dim(casos.vph) [1] 1190 26 "],
["estadística-descriptiva.html", "4 Estadística descriptiva 4.1 Variables categóricas 4.2 Tabla de contingencia 4.3 Variables continuas", " 4 Estadística descriptiva Ahora empezaremos a ver la potencia de R. No sólo se hacen librerías para el análisis estadístico de datos, también se hacen librerías para visualizar resultados de forma gráfica, hacer análisis descriptivos rápidos o crear tablas de artículos de forma sencilla. Algunas de estas librerías las iremos viendo durante el curso. Empecemos con algunas librerías para resumir de forma rápida nuestras variables. Para ello necesitamos instalar las siguientes librerías que iremos viendo a lo largo del curso install.packages(&quot;summarytools&quot;, &quot;compareGroups&quot;) 4.1 Variables categóricas La librería summarytools es muy potente. Por ejemplo, podemos obtener un resumen para las variables categóricas (por ejemplo para saber cuantos casos y controles tenemos) con la función freq() library(summarytools) freq(multicentric$status) Frequencies multicentric$status Type: Character Freq % Valid % Valid Cum. % Total % Total Cum. ------------- ------ --------- -------------- --------- -------------- Caso 1489 51.17 51.17 51.17 51.17 Control 1421 48.83 100.00 48.83 100.00 &lt;NA&gt; 0 0.00 100.00 Total 2910 100.00 100.00 100.00 100.00 Notemos que antes hay que cargar la librería para que R encuentre la función freq(), no es suficiente con instalar la librería, luego hay que cargarla. También vemos que esta función no describe las variables categóricas (ver warning). Podemos evitar que salgan los missings (NA) y hacer más compacta la tabla con la instrucción freq(multicentric$status, report.nas = FALSE, headings = FALSE) Freq % % Cum. ------------- ------ -------- -------- Caso 1489 51.17 51.17 Control 1421 48.83 100.00 Total 2910 100.00 100.00 Si queremos que lo haga para todas las variables categóricas, funciona así de simple freq(multicentric, report.nas = FALSE, headings = FALSE) multicentric$pais Freq % % Cum. --------------- ------ -------- -------- Brasil 347 11.92 11.92 Colombia 323 11.10 23.02 Espaia 376 12.92 35.95 Filipinas 636 21.86 57.80 Marruecos 332 11.41 69.21 Peri 312 10.72 79.93 Tailandia 584 20.07 100.00 Total 2910 100.00 100.00 multicentric$status Freq % % Cum. ------------- ------ -------- -------- Caso 1489 51.17 51.17 Control 1421 48.83 100.00 Total 2910 100.00 100.00 multicentric$niveledu Freq % % Cum. ------------------- ------ -------- -------- ninguno 681 23.40 23.40 primaria 1446 49.69 73.09 secundaria 673 23.13 96.22 ticnico 62 2.13 98.35 universitario 48 1.65 100.00 Total 2910 100.00 100.00 multicentric$fumar Freq % % Cum. ---------------- ------ -------- -------- ex-fumador 223 7.66 7.66 fumador 292 10.03 17.70 no fumador 2395 82.30 100.00 Total 2910 100.00 100.00 multicentric$regcompa Freq % % Cum. ----------- ------ -------- -------- 1 2147 74.39 74.39 2 553 19.16 93.56 3 142 4.92 98.48 4 32 1.11 99.58 5 8 0.28 99.86 6 4 0.14 100.00 Total 2886 100.00 100.00 multicentric$totcompa Freq % % Cum. ----------- ------ -------- -------- &gt;=100 7 0.25 0.25 1 1947 68.51 68.75 11-20 9 0.32 69.07 2-3 749 26.35 95.43 21-50 7 0.25 95.67 4-10 122 4.29 99.96 51-99 1 0.04 100.00 Total 2842 100.00 100.00 multicentric$ets Freq % % Cum. ----------- ------ -------- -------- no 1763 64.65 64.65 si 964 35.35 100.00 Total 2727 100.00 100.00 multicentric$co Freq % % Cum. ----------- ------ -------- -------- no 1977 67.94 67.94 si 933 32.06 100.00 Total 2910 100.00 100.00 multicentric$condon Freq % % Cum. ----------- ------ -------- -------- no 2540 87.29 87.29 si 370 12.71 100.00 Total 2910 100.00 100.00 multicentric$embara Freq % % Cum. ----------- ------ -------- -------- no 109 3.75 3.75 si 2801 96.25 100.00 Total 2910 100.00 100.00 multicentric$nembara Freq % % Cum. ----------- ------ -------- -------- 1 155 5.55 5.55 2 322 11.52 17.07 3 383 13.70 30.77 4 373 13.35 44.11 5 338 12.09 56.21 6 299 10.70 66.91 7 257 9.19 76.10 8 195 6.98 83.08 9 138 4.94 88.01 10 105 3.76 91.77 11 71 2.54 94.31 12 63 2.25 96.57 13 32 1.14 97.71 14 23 0.82 98.53 15 21 0.75 99.28 16 8 0.29 99.57 17 6 0.21 99.79 18 3 0.11 99.89 20 1 0.04 99.93 22 1 0.04 99.96 25 1 0.04 100.00 Total 2795 100.00 100.00 multicentric$pap Freq % % Cum. ----------- ------ -------- -------- no 1291 45.05 45.05 si 1575 54.95 100.00 Total 2866 100.00 100.00 multicentric$vph Freq % % Cum. -------------- ------ -------- -------- negativo 1077 44.23 44.23 positivo 1358 55.77 100.00 Total 2435 100.00 100.00 multicentric$edad1sex3 Freq % % Cum. ----------- ------ -------- -------- 0 1379 47.73 47.73 1 1510 52.27 100.00 Total 2889 100.00 100.00 multicentric$edad1sex4 Freq % % Cum. ------------- ------ -------- -------- (5,16] 736 25.48 25.48 (16,19] 872 30.19 55.68 (19,22] 596 20.64 76.32 (22,52] 684 23.68 100.00 Total 2888 100.00 100.00 multicentric$edad1sex5 Freq % % Cum. ----------- ------ -------- -------- &lt;14 257 8.90 8.90 15-18 1122 38.84 47.73 19+ 1510 52.27 100.00 Total 2889 100.00 100.00 multicentric$fumarNewCat Freq % % Cum. ----------- ------ -------- -------- No 2618 89.97 89.97 Si 292 10.03 100.00 Total 2910 100.00 100.00 4.2 Tabla de contingencia Para crear una tabla de contingencia y ver cómo se distribuyen los casos y controles según su infección por vph podríamos usar la función ctable() ctable(multicentric$status, multicentric$vph, prop=&quot;r&quot;) Cross-Tabulation, Row Proportions status * vph Data Frame: multicentric --------- ----- -------------- -------------- ------------- --------------- vph negativo positivo &lt;NA&gt; Total status Caso 81 ( 5.4%) 1190 (79.9%) 218 (14.6%) 1489 (100.0%) Control 996 (70.1%) 168 (11.8%) 257 (18.1%) 1421 (100.0%) Total 1077 (37.0%) 1358 (46.7%) 475 (16.3%) 2910 (100.0%) --------- ----- -------------- -------------- ------------- --------------- el argumento prop nos sirve para indicar si queremos las proporciones por fila (‘r’) o columna (‘c’). Podmeos eliminar la columna de missings indicando que el argumento useNA sea “no” ctable(multicentric$status, multicentric$vph, useNA=&quot;no&quot;, prop=&quot;r&quot;) Cross-Tabulation, Row Proportions status * vph Data Frame: multicentric --------- ----- -------------- -------------- --------------- vph negativo positivo Total status Caso 81 ( 6.4%) 1190 (93.6%) 1271 (100.0%) Control 996 (85.6%) 168 (14.4%) 1164 (100.0%) Total 1077 (44.2%) 1358 (55.8%) 2435 (100.0%) --------- ----- -------------- -------------- --------------- 4.3 Variables continuas Para las variables continuas podemos usar la función descr(). Por ejemplo, si queremos ver los principales estadísticos de la variable edad de la primera relación sexual (variable edad1sex) escribiríamos descr(multicentric$edad1sex) Descriptive Statistics multicentric$edad1sex N: 2910 edad1sex ----------------- ---------- Mean 19.73 Std.Dev 4.73 Min 5.00 Q1 16.00 Median 19.00 Q3 22.00 Max 52.00 MAD 4.45 IQR 6.00 CV 0.24 Skewness 1.10 SE.Skewness 0.05 Kurtosis 2.44 N.Valid 2889.00 Pct.Valid 99.28 Una de las principales ventajas de R es que usa un lenguaje de programación orientado a objetos. En palabras sencillas, esto implica que una misma función se puede aplicar a distintos tipos de objetos y la función ya sabe qué hacer. En este caso, si aplicamos la función desrc() a toda nuestra base de datos, lo que hace es buscar todas las variables continuas, y resumirlas. descr(multicentric) Descriptive Statistics multicentric N: 2910 durco edad edad1pap edad1sex edad1sex2 edad1sex3 edademba ----------------- -------- --------- ---------- ---------- ----------- ----------- ---------- Mean 6.40 48.86 39.91 19.73 1.73 0.52 21.32 Std.Dev 6.16 11.92 13.66 4.73 4.73 0.50 4.80 Min 1.00 20.00 14.00 5.00 -13.00 0.00 10.00 Q1 1.00 40.00 29.00 16.00 -2.00 0.00 18.00 Median 4.00 49.00 38.00 19.00 1.00 1.00 20.00 Q3 9.00 58.00 50.00 22.00 4.00 1.00 24.00 Max 34.00 84.00 80.00 52.00 34.00 1.00 52.00 MAD 4.45 13.34 14.83 4.45 4.45 0.00 4.45 IQR 8.00 18.00 21.00 6.00 6.00 1.00 6.00 CV 0.96 0.24 0.34 0.24 2.74 0.96 0.23 Skewness 1.53 0.12 0.46 1.10 1.10 -0.09 1.02 SE.Skewness 0.08 0.05 0.06 0.05 0.05 0.05 0.05 Kurtosis 2.43 -0.66 -0.58 2.44 2.44 -1.99 1.50 N.Valid 923.00 2910.00 1519.00 2889.00 2889.00 2889.00 2795.00 Pct.Valid 31.72 100.00 52.20 99.28 99.28 99.28 96.05 Table: Table continues below edfinco edinico ident nembara regcompa ----------------- --------- --------- ---------- --------- ---------- Mean 33.72 26.75 11550.22 5.55 1.34 Std.Dev 7.76 6.64 993.30 3.24 0.67 Min 15.00 11.00 10001.00 1.00 1.00 Q1 28.00 22.00 10728.00 3.00 1.00 Median 33.00 26.00 11455.50 5.00 1.00 Q3 39.00 31.00 12183.00 7.00 2.00 Max 62.00 48.00 13701.00 25.00 6.00 MAD 7.41 7.41 1078.59 2.97 0.00 IQR 11.00 9.00 1454.50 4.00 1.00 CV 0.23 0.25 0.09 0.58 0.50 Skewness 0.32 0.50 0.42 0.99 2.42 SE.Skewness 0.08 0.08 0.05 0.05 0.05 Kurtosis -0.16 -0.16 -0.72 1.21 7.44 N.Valid 923.00 931.00 2910.00 2795.00 2886.00 Pct.Valid 31.72 31.99 100.00 96.05 99.18 Si queremos tener esta descriptiva según una segunda variable categórica como es habitual en la mayoría de análisis estadísticos (por ejemplo entre grupos de comparación o para casos y controles) podemos hacerlo también. Supongamos que queremos tener una descriptiva de las variables categóricas según la variable caso-control (status). Para ello, deberíamos usar la función stby() e indicar en el argumento INDICES nuestra variable por la que queremos separar los análisis. stby(multicentric, INDICES = multicentric$status, FUN = descr, stats = &quot;common&quot;, transpose = TRUE) Descriptive Statistics multicentric Group: status = Caso N: 1489 Mean Std.Dev Min Median Max N.Valid Pct.Valid --------------- ---------- --------- ---------- ---------- ---------- --------- ----------- durco 7.14 6.25 1.00 5.00 31.00 490.00 32.91 edad 49.53 11.85 20.00 49.00 84.00 1489.00 100.00 edad1pap 42.95 14.56 14.00 42.00 80.00 825.00 55.41 edad1sex 18.72 4.34 6.00 18.00 52.00 1486.00 99.80 edad1sex2 0.72 4.34 -12.00 0.00 34.00 1486.00 99.80 edad1sex3 0.42 0.49 0.00 0.00 1.00 1486.00 99.80 edademba 20.36 4.41 10.00 20.00 52.00 1453.00 97.58 edfinco 33.99 7.78 16.00 34.00 58.00 490.00 32.91 edinico 26.12 6.66 13.00 25.00 48.00 492.00 33.04 ident 11581.04 966.97 10002.00 11505.00 13581.00 1489.00 100.00 nembara 5.95 3.26 1.00 5.00 25.00 1453.00 97.58 regcompa 1.45 0.75 1.00 1.00 6.00 1484.00 99.66 Group: status = Control N: 1421 Mean Std.Dev Min Median Max N.Valid Pct.Valid --------------- ---------- --------- ---------- ---------- ---------- --------- ----------- durco 5.57 5.96 1.00 3.00 34.00 433.00 30.47 edad 48.16 11.97 20.00 48.00 82.00 1421.00 100.00 edad1pap 36.29 11.52 16.00 35.00 75.00 694.00 48.84 edad1sex 20.80 4.89 5.00 20.00 46.00 1403.00 98.73 edad1sex2 2.80 4.89 -13.00 2.00 28.00 1403.00 98.73 edad1sex3 0.63 0.48 0.00 1.00 1.00 1403.00 98.73 edademba 22.36 4.99 13.00 22.00 41.00 1342.00 94.44 edfinco 33.41 7.74 15.00 33.00 62.00 433.00 30.47 edinico 27.46 6.56 11.00 27.00 47.00 439.00 30.89 ident 11517.93 1019.50 10001.00 11404.00 13701.00 1421.00 100.00 nembara 5.12 3.15 1.00 4.00 20.00 1342.00 94.44 regcompa 1.23 0.55 1.00 1.00 5.00 1402.00 98.66 El argumento stats=\"common\" lo ponemos para que saque menos estadísticos (sólo los más comunes), pero si no ponemos nada los saca todos y el argumento transpose = TRUE sirve para trasnponer la tabla de resultados. NOTA: cuando hablemos de informes reproducibles y de Rmarkdown veremos que estas tablas quedarán mucho mejor cuando mostremos nuestros resultados con HTML o incluso PDFs o documentos Word … pero eso será al final del curso. Podríamos pensar que este tipo de descriptivas también las obtenemos con SPSS o Stata, pero …. tenemos más opciones que nos facilitan mucho la vida como estadísticos. En este caso, podemos resumir toda nuestra base de datos (tanto variables continuas como categóricas) con la función dfSummary() y obtendríamos este output dfSummary(multicentric) Data Frame Summary multicentric Dimensions: 2910 x 26 Duplicates: 0 No Variable Stats / Values Freqs (% of Valid) Graph Valid Missing 1 ident [integer] Mean (sd) : 11550.2 (993.3) min 2910 distinct values 2910 (100%) 0 (0%) 2 pais [character] 1. Brasil 2. Colombia 3. Espaia 4. Filipinas 5. Marruecos 6. Peri 7. Tailandia 347(11.9%)323(11.1%)376(12.9%)636(21.9%)332(11.4%)312(10.7%)584(20.1%) 2910 (100%) 0 (0%) 3 status [character] 1. Caso 2. Control 1489(51.2%)1421(48.8%) 2910 (100%) 0 (0%) 4 edad [integer] Mean (sd) : 48.9 (11.9) min 62 distinct values 2910 (100%) 0 (0%) 5 niveledu [character] 1. ninguno 2. primaria 3. secundaria 4. ticnico 5. universitario 681(23.4%)1446(49.7%)673(23.1%)62(2.1%)48(1.6%) 2910 (100%) 0 (0%) 6 fumar [character] 1. ex-fumador 2. fumador 3. no fumador 223(7.7%)292(10.0%)2395(82.3%) 2910 (100%) 0 (0%) 7 edad1sex [integer] Mean (sd) : 19.7 (4.7) min 40 distinct values 2889 (99.28%) 21 (0.72%) 8 regcompa [integer] Mean (sd) : 1.3 (0.7) min 1:2147(74.4%)2:553(19.2%)3:142(4.9%)4:32(1.1%)5:8(0.3%)6:4(0.1%) 2886 (99.18%) 24 (0.82%) 9 totcompa [character] 1. >=100 2. 1 3. 11-20 4. 2-3 5. 21-50 6. 4-10 7. 51-99 7(0.2%)1947(68.5%)9(0.3%)749(26.4%)7(0.2%)122(4.3%)1(0.0%) 2842 (97.66%) 68 (2.34%) 10 ets [character] 1. no 2. si 1763(64.6%)964(35.4%) 2727 (93.71%) 183 (6.29%) 11 co [character] 1. no 2. si 1977(67.9%)933(32.1%) 2910 (100%) 0 (0%) 12 edinico [integer] Mean (sd) : 26.8 (6.6) min 37 distinct values 931 (31.99%) 1979 (68.01%) 13 edfinco [integer] Mean (sd) : 33.7 (7.8) min 45 distinct values 923 (31.72%) 1987 (68.28%) 14 durco [integer] Mean (sd) : 6.4 (6.2) min 33 distinct values 923 (31.72%) 1987 (68.28%) 15 condon [character] 1. no 2. si 2540(87.3%)370(12.7%) 2910 (100%) 0 (0%) 16 embara [character] 1. no 2. si 109(3.8%)2801(96.2%) 2910 (100%) 0 (0%) 17 edademba [integer] Mean (sd) : 21.3 (4.8) min 34 distinct values 2795 (96.05%) 115 (3.95%) 18 nembara [integer] Mean (sd) : 5.6 (3.2) min 21 distinct values 2795 (96.05%) 115 (3.95%) 19 pap [character] 1. no 2. si 1291(45.1%)1575(54.9%) 2866 (98.49%) 44 (1.51%) 20 edad1pap [integer] Mean (sd) : 39.9 (13.7) min 65 distinct values 1519 (52.2%) 1391 (47.8%) 21 vph [character] 1. negativo 2. positivo 1077(44.2%)1358(55.8%) 2435 (83.68%) 475 (16.32%) 22 edad1sex2 [numeric] Mean (sd) : 1.7 (4.7) min 40 distinct values 2889 (99.28%) 21 (0.72%) 23 edad1sex3 [numeric] Min : 0 Mean : 0.5 Max : 1 0:1379(47.7%)1:1510(52.3%) 2889 (99.28%) 21 (0.72%) 24 edad1sex4 [factor] 1. (5,16] 2. (16,19] 3. (19,22] 4. (22,52] 736(25.5%)872(30.2%)596(20.6%)684(23.7%) 2888 (99.24%) 22 (0.76%) 25 edad1sex5 [factor] 1. 257(8.9%)1122(38.8%)1510(52.3%) 2889 (99.28%) 21 (0.72%) 26 fumarNewCat [character] 1. No 2. Si 2618(90.0%)292(10.0%) 2910 (100%) 0 (0%) Generated by summarytools 0.9.6 (R version 4.0.2)2020-11-01 "],
["pruebas-de-hipótesis.html", "5 Pruebas de Hipótesis 5.1 Prueba de hipótesis para la media, \\(\\mu\\), de una población normal 5.2 Prueba de hipótesis para la proporción \\(p\\) de una población 5.3 Prueba de hipótesis para la razón de varianzas \\(\\sigma_1^2 / \\sigma_2^2\\) 5.4 Prueba de hipótesis para la igualdad de medias \\(\\mu_A = \\mu_B\\) 5.5 Prueba de hipótesis para la igualdad de más de dos medias (ANOVA) 5.6 Prueba de hipótesis para la igualdad de proporciones \\(p_A = p_B\\) 5.7 Pruebas no paramétricas", " 5 Pruebas de Hipótesis En la siguiente figura podemos observar un esquema general de cómo abordar un problema científico desde un punto de vista estadístico. Partimos de una pregunta científica que nos planteamos sobre nuestra población de estudio. Esta pregunta debe ser traducida a una pregunta estadística que nos permita saber cómo abordarla desde un punto de vista matemático o estadístico. Esquema investigación científica Por ejemplo, imaginemos que estamos interesados en saber si el consumo de aspirina reduce el riesgo de sufrir un infarto de miocardio. Hay un método muy sencillo de saber qué problema necesitamos abordar desde un punto de vista estadístico a partir de nuestra pregunta científica y es conocer la naturaleza de nuestros datos. En este caso, nuestra variable resultado sería sufrir o no un infarto, por lo que estaríamos ante una variable binaria. Este tipo de variables se resumen con la frecuencia relativa o proporciones. De esta forma, la pregunta estadística se traduciría cómo: ¿La proporción de personas que sufren un infarto es igual en aquellas personas que toman aspirina que en las que no toma? Para contestar a esta pregunta, el método científico nos indica que debemos tomar una muestra aleatoria (para garantizar representatividad de nuestra problación) que describiremos con métodos descriptivos vistos en el tema anterior. También podemos realizar un experimento o diseñar un estudio que nos permita contestar a nuestra pregunta cienífica. Existen muchos tipos de diseños, que se suponen que son familiares para el alumno. Para nuestro ejemplo podríamos, entre otras opciones, diseñar un estudio en el que estudiáramos personas que han sufrido un infarto y otro grupo control de la misma edad y sexo a los que preguntaríamos si han tomado o no aspirina durante los últimos años (diseño caso-control). Entonces, podríamos compararla proporción de infartos entre las personas que toman y no toman aspirina. Empezaríamos por mostrar estas diferencias de forma visual con, por ejemplo, un gráfico de barras (que es como se visualizan las variables categóricas). Ahora nuestra siguiente pregunta sería saber si las diferencias que observamos son reales o son debidas al azar (es decir, por no estudiar toda la población y si una muestra aleatoria). Para demostrar que estas diferencias son reales (e.g estadísticamente significativas) debemos realizar lo que se conoce como inferencia estadística, que en este caso correspondería a una prueba de hipótesis. En el caso que nuestra pregunta científica esté asociada a una variable continua se abordaría de la misma forma. La única diferencia es que la prueba de hipótesis planteada sería distinta. Por ejemplo, supongamos que queremos saber si el consumo de café aumenta la tensión arterial. En ese caso, nuestra variable resultado es tensión arterial, que al ser continua se resume con la media. Así pues, nuestra pregunta estadística sería: ¿La media de tensión arterial es igual en los consumidores de café que en los que no consumen? En consecuencia, las pruebas que nos planteamos para comparar ambos grupos (A y B) en cada ejemplo sería \\[H_0: p_A = p_B\\] y \\[H_0: \\bar{x}_A = \\bar{x}_B\\] respectivamente. Una vez planteadas las pruebas de hipótesis, basta con usar un software estadístico para calcular el p-valor que es la medida que nos indica si las diferencias observadas en nuestra muestra son reales o son debidas al azar. En otras palabras, demostramos si las diferencias observadas son estadísticamente significativas. Como decimos, el proceso para determinar esta significación estadística se basa en el cálculo del p-valor, y consideraremos que las diferencias serán estadísticamente significativas si el p-valor\\(&lt;0.05\\) y no cuando ocurra lo contrario. A este valor de \\(0.05\\) se le conoce como el nivel de significación estadística (\\(\\alpha\\)) y es el valor que asumimos como riesgo a equivocarnos cuando las diferencias no son reales. En la siguiente figura podemos ver un resumen del tipo de errores que podemos cometer cuando llevamos a cabo una prueba de hipótesis A modo de resumen podríamos decir que los pasos en un proceso de investigación serían: Formular hipotesis nula (y alternativa) Decidir el nivel de significanza estadística (\\(\\alpha\\)) Eligir un test estadístico a utilizarse (que dependerá del tipo de variable que estudiemos) Calcular el p-valor con ese test y decidir si rechazamos \\(H_0\\) o no. Para entender un poco mejor este procedimiento, podems compararlo con el simil de un jurado. Es importante notar que siempre partimos de la hipótesis nula y que queremos dar evidencias a partir de nuestros datos, nunca hacemos lo contrario, al igual que pasa en un juicio Símil del jurado en pruebas de hipótesis A continuación explicaremos cómo llevar a cabo estas pruebas de hipótesis con R en función de nuestra variable de interés para las siguientes pruebas. En este capítulo se muestran las funciones que hay disponibles en R para realizar prueba de hipótesis para: La media \\(\\mu\\), La proporción \\(p\\), La razón de varianzas \\(\\sigma_A^2 / \\sigma_B^2\\), La igualdad de medias \\(\\mu_A = \\mu_B\\) para muestras independientes, La igualdad de medias para más de dos grupos (ANOVA), y La igualdad de proporciones \\(p_A = p_B\\). Pruebas no-paramétricas Para ilustrar estos cálculos usaremos la base de datos multicentric.txt que hemos trabajado en capítulos anteriores. Para ello, recordemos que primero debemos cargar los datos en R tal y como se ha descrito en el capítulo @ref{importar}, o bien con el menú o bien con la siguiente instrucción. multicentric &lt;- read.delim(&quot;datos/multicentric.txt&quot;) NOTA: recordad que para que esta instrucción funcione debéis cambiar el directorio de trabajo a la carpeta que contenga este fichero. 5.1 Prueba de hipótesis para la media, \\(\\mu\\), de una población normal Este test se llevará a cabo cuando nuestra pregunta científica se interese por una variable resultado de tipo continua. Para realizar este tipo de prueba se puede usar la función t.test que tiene la siguiente estructura. t.test(x, y = NULL, alternative = c(&quot;two.sided&quot;, &quot;less&quot;, &quot;greater&quot;), mu = 0, paired = FALSE, var.equal = FALSE, conf.level = 0.95, ...) Los argumentos a definir dentro de t.test para hacer la prueba son: x: vector numérico con los datos. alternative: tipo de hipótesis alterna. Los valores disponibles son \"two.sided\" cuando la hipótesis alterna es \\(\\neq\\), \"less\" para el caso \\(&lt;\\) y \"greater\" para \\(&gt;\\). mu: valor de referencia de la prueba. conf.level: nivel de confianza para reportar el intervalo de confianza asociado (opcional). Ejemplo Supongamos que queremos saber si la edad de la primera relación sexual es superior a los 18 años. Lo primero que debemos hacer es comprobar si los datos siguene una distribución normal. Para ello usaremos una libería que tiene una batería de 10 pruebas distintas que se llama nortest. Para usarla, primero hay que instalarla install.packages(&quot;nortest&quot;) y luego podemos evaluar si la variable es normal usando cualquiera de los tests implementados, de la siguiente forma library(nortest) lillie.test(multicentric$edad1sex) Lilliefors (Kolmogorov-Smirnov) normality test data: multicentric$edad1sex D = 0.12136, p-value &lt; 2.2e-16 Nosotros hemos usado la prueba de Lilliefors (Kolmogorov-Smirnov) pero se pueden usar otras como la de Anderson-Darling (función ad.test) o Shapiro-Francia (función sf.test) entre muchas otras. Podemos ver que rechazamos la hipóteisis nula de normalidad ($p&lt;0.05), por lo que necesitmos solventar este problema. Normalmente esto se hace transformando los datos usando la transformación logarítmica. Luego volvemos a testar la normalidad para ver si podemos aplicar el test para la media. Para ello crearemos primero una nueva variable que llamaremos edad1sex2. library(tidyverse) multicentric &lt;- mutate(multicentric, edad1sex2 = log(edad1sex)) y ahora aplicamos el test a la nueva variable lillie.test(multicentric$edad1sex2) Lilliefors (Kolmogorov-Smirnov) normality test data: multicentric$edad1sex2 D = 0.088069, p-value &lt; 2.2e-16 Vemos que la variable sigue sin ser normal. También podríamos verlo de forma gráfica hist(multicentric$edad1sex2, xlab=&quot;log(edad primera relación sexual)&quot;, main=&quot;&quot;) Observamos que la cola de la izquierda es más pesada que la de la derecha. Es decir, la distribución sigue sin ser simétrica que es una de las características principales de las variables normales. Ahora tenemos dos opciones: Buscar otro tipo de transformación que garantice la normalidad Usar un test no paramétrico. La segunda opción la veremos en capítulos más adelante y es la que recomendamos realizar ya que la primera opción tiene sus inconvenientes, sobre todo si queremos interpretar los resultados ya que la transformación a aplicar (Yeo-Johnson) puedes tener una forma muy complicada. Si alguien quiere hacer esta transformación en R existen varias librerías que pueden hacer esta transformación como la libería bestNormalize. En este trabajo asumiremos que la variable edad1sex es normal e ilustraremos como realizar el test que estabamos interesados: \\[H_0: \\text{edad1sex = 18}\\] \\[H_1: \\text{edad1sex &gt; 18}\\] Esta prueba de hipótesis se puede realizar usando la función t.test por medio del siguiente código. t.test(multicentric$edad1sex, alternative=&quot;greater&quot;, mu=18) One Sample t-test data: multicentric$edad1sex t = 19.639, df = 2888, p-value &lt; 2.2e-16 alternative hypothesis: true mean is greater than 18 95 percent confidence interval: 19.58443 Inf sample estimates: mean of x 19.72932 Como el valor-P es &lt;0.05 y por lo tanto menor que el nivel de significanción del 5%, tenemos evidencias para rechazar la hipótesis nula, es decir, las evidencias son suficientes para afirmar que la edad de la primera relación sexual no ocurre a los 18 años. NOTA: no es habitual hacer test unilaterales (alternativa mayor o menor) ya que está recomendado hacer bi-laterales (el valor por defecto del argumento alternative) pero hemos querido hacer este ejemplo para ilustrar como plantear este tipo de pruevas de hipótesis. 5.2 Prueba de hipótesis para la proporción \\(p\\) de una población Este test se llevará a cabo cuando nuestra pregunta científica se interese por una variable resultado binaria o categórica. Existen varias pruebas para testar si la propoción \\(p\\) de una distribución binomial (porque tenemos \\(n\\) individuos que siguen una Bernoulli de parámetro \\(p\\)) sigue un valor predeterminado. Prueba de Wald, Prueba \\(\\Chi^2\\) de Pearson, Prueba binomial exacta. 5.2.1 Prueba de Wald Esta prueba se recomienda usar cuando se tiene un tamaño de muestra \\(n\\) suficientemente grande para poder usar la distribución normal como aproximación de la distribución binomial. En esta prueba el estadístico está dado por \\[z=\\frac{\\hat{p}-p_0}{\\sqrt{\\frac{p_0(1-p_0)}{n}}},\\] donde \\(\\hat{p}\\) es la proporción muestral calculada como el cociente entre el número de éxitos \\(x\\) observados en los \\(n\\) ensayos y \\(p_0\\) es el valor de referencia de las hipótesis. El estadístico \\(z\\) tiene distribución \\(N(0, 1)\\) cuando \\(n \\to \\infty\\). Para realizar esta prueba en R no hay una función y debemos escribir la líneas de código para obtener el estadístico y el valor-P de la prueba. Dado que estamos en un curso introductorio, obviaremos esta solución que aunque no es compleja, requiere escribir algo de código en R y no usar una función 5.2.2 Prueba \\(\\Chi^2\\) de Pearson Esta prueba también require de un tamaño muestral \\(n\\) grande. Para realizar los cálculos se usa la función prop.test que tiene la siguiente estructura. prop.test(x, n, p = NULL, alternative = c(&quot;two.sided&quot;, &quot;less&quot;, &quot;greater&quot;), conf.level = 0.95, correct = TRUE) Los argumentos a definir dentro de prop.test para hacer la prueba son: x: número de éxitos en la muestra. n: número de observaciones en la muestra. alternative: tipo de hipótesis alterna. Los valores disponibles son \"two.sided\" cuando la alterna es \\(\\neq\\), \"less\" para el caso \\(&lt;\\) y \"greater\" para \\(&gt;\\). p: valor de referencia de la prueba. correct: valor lógico para indicar si se usa la corrección de Yates. conf.level: nivel de confianza para reportar el intervalo de confianza asociado (opcional). Ejemplo Supongamos que queremos saber si en nuestro estudio de cáncer cervical, la proporción de gente que se realiza una prueba del virus de papiloma humano (variable pap) es del 55% ya que ese es el porcentaje de pruebas que se realiza en España y lo consideramos como el de referencia. En este problema interesa probar lo siguiente: \\[H_0: p = 0.55\\] \\[H_1: p \\ne 0.55\\] La forma de usar la función prop.test para realizar la prueba se muestra a continuación. Primero necesitamos saber cuántas mujeres se hacen o no la prueba del virus de papiloma humano y cuántas mujeres tenemos en total. Esto lo podemos saber con: nrow(multicentric) [1] 2910 table(multicentric$pap) no si 1291 1575 Entonces usamos la función como prop.test(x=1575, n=2910, p=0.55) 1-sample proportions test with continuity correction data: 1575 out of 2910, null probability 0.55 X-squared = 0.86778, df = 1, p-value = 0.3516 alternative hypothesis: true p is not equal to 0.55 95 percent confidence interval: 0.5229179 0.5594466 sample estimates: p 0.5412371 Como el p-valor es &gt;0.05, concluimos que no tenemos evidencias para afirmar que el porcentaje de mujeres que se hacen la prueba del virus de papiloma humano sea distinta a la de España (0.55). NOTA: nunca aceptamos la hipótesis nula y decimos que nuestra proporción es del 55%. 5.2.3 Prueba binomial exacta Esta prueba se recomienda cuando tenemos un tamaño muestral \\(n\\) muy pequeño (menor de 30). Para realizar la prueba binomial exacta se usa la función binom.test que tiene la siguiente estructura. binom.test(x, n, p = 0.5, alternative = c(&quot;two.sided&quot;, &quot;less&quot;, &quot;greater&quot;), conf.level = 0.95) Los argumentos a definir dentro de binom.test para hacer la prueba son: x: número de éxitos en la muestra. n: número de observaciones en la muestra. alternative: tipo de hipótesis alterna. Los valores disponibles son \"two.sided\" cuando la alterna es \\(\\neq\\), \"less\" para el caso \\(&lt;\\) y \"greater\" para \\(&gt;\\). p: valor de referencia de la prueba. conf.level: nivel de confianza para reportar el intervalo de confianza asociado (opcional). En nuestro ejemplo anterior tendríamos que escribir binom.test(x=1575, n=2910, p=0.55) Exact binomial test data: 1575 and 2910 number of successes = 1575, number of trials = 2910, p-value = 0.3421 alternative hypothesis: true probability of success is not equal to 0.55 95 percent confidence interval: 0.5229268 0.5594644 sample estimates: probability of success 0.5412371 Notemos que el p-valor es muy similar al anterior, puesto que estamos con una muestra muy grande. 5.3 Prueba de hipótesis para la razón de varianzas \\(\\sigma_1^2 / \\sigma_2^2\\) Esta prueba es importante ya que para comparar dos medias (que es el tipo de prubas que más se suele hacer en investigación biomédica) a parte de comprobar que nuestra variable de interés es normal, debemos comprobar que la varianza entre los dos grupos es la misma. O en otras palabras que la razón de la varianza de cada grupo es 1: \\[H_0: \\frac{\\sigma_{A}^2}{\\sigma_{B}^2} = 1\\] \\[H_0: \\frac{\\sigma_{A}^2}{\\sigma_{B}^2} \\neq 1\\] Para realizar este tipo de prueba se puede usar la función var.test. Ejemplo Supongamos que queremos verificar si la edad de la primera relación sexual (que hemos asumido que es normal) es igual entre casos y controles (variable status). El p-valor correspondiente a esta prueba se calcularía mediante: var.test(edad1sex ~ status, data=multicentric) F test to compare two variances data: edad1sex by status F = 0.78849, num df = 1485, denom df = 1402, p-value = 6.426e-06 alternative hypothesis: true ratio of variances is not equal to 1 95 percent confidence interval: 0.7110839 0.8741965 sample estimates: ratio of variances 0.7884945 El símbolo ~ (que se puede escribir con AltGr + 4 y espacio) indica que queremos comparar la varianza de la variable que hay a la izquierda en función de la variable que hay en la derecha. Notemos que hay que indicar a R donde están las variables edad1sex y status, por eso escribimos data=multicentric. Observamos que el p-valor es &lt;0.05, por lo que tenemos evidencias para decir que la variabilidad de la edad en la primera relación sexual (edad1sex) es distinta entre los casos y los controles. Esto no es un problema desde un punto de vista práctico. Simplemente debemos tenerlo en cuenta a la hora de hacer un test para comparar si esta variable es un factor que se relaciona con tener cáncer o no, tal y como veremos en la siguiente sección. 5.4 Prueba de hipótesis para la igualdad de medias \\(\\mu_A = \\mu_B\\) En este caso, estamos interesados en conocer si la media de una variable continua es igual en dos grupos. Para realizar este tipo de prueba se puede usar la función t.test que implementa el test de la t de Student (t-test) y que tiene la siguiente estructura. t.test(x, y = NULL, alternative = c(&quot;two.sided&quot;, &quot;less&quot;, &quot;greater&quot;), mu = 0, paired = FALSE, var.equal = FALSE, conf.level = 0.95, ...) Los argumentos a definir dentro de t.test para hacer la prueba son: x: vector numérico con la información de la muestra 1, y: vector numérico con la información de la muestra 2, alternative: tipo de hipótesis alterna. Los valores disponibles son \"two.sided\" cuando la alterna es \\(\\neq\\), \"less\" para el caso \\(&lt;\\) y \"greater\" para \\(&gt;\\). mu: valor de referencia de la prueba (opcinal, no necesario la mayoría de veces ya que siempre queremos comparar si son iguales lo que implica que la diferencia es 0 que es el valor por defecto). var.equal=TRUE: indica que las varianzas son desconocidas pero iguales. Si no lo son, basta con poner var.equal=FALSE. conf.level: nivel de confianza para reportar el intervalo de confianza asociado (opcional). Ejemplo Siguiendo con el ejemplo anterior, investiguemos si la edad de la primera relación sexual está asociada con tener cáncer cervical. En este caso plantearíamos la prueba estadística: \\[H_0: \\mu_\\text{controles} = \\mu_\\text{casos}\\] \\[H_1: \\mu_\\text{controles} \\neq \\mu_\\text{casos}\\] Que puede llevarse a cabo mediante: t.test(edad1sex ~ status, data=multicentric, var.equal=FALSE) Welch Two Sample t-test data: edad1sex by status t = -12.073, df = 2800.9, p-value &lt; 2.2e-16 alternative hypothesis: true difference in means is not equal to 0 95 percent confidence interval: -2.420601 -1.744185 sample estimates: mean in group Caso mean in group Control 18.71803 20.80043 Notemos que si en la prueba anterior de igualdad de varianzas, no hubiéramos rechazado la hipótesis nula, ahora no sería necesario poner var.equal=FALSE ya que por defecto ese argumento es TRUE que indicaría que las varianzas son iguales. Como en nuestro caso hemos rechazado dicha hipótesis, debemos cambiar este argumento de la función. El resto de la función es similar al caso anterior. 5.5 Prueba de hipótesis para la igualdad de más de dos medias (ANOVA) A veces, estamos interesados en comparar la media de nuestra variable de interés para más de dos grupos. En este caso, no podemos usar el t-test anteriormente descrito. La método de análisis de varianza (ANOVA) es el test que se emplea para el estudio del efecto de uno o más factores (cada uno con dos o más niveles) sobre la media de una variable continua. Es por lo tanto el test estadístico a emplear cuando se desea comparar las medias de dos o más grupos. La prueba estadística puede plantearse como: \\[H_0: \\mu_A = \\mu_B = \\cdots = \\mu_K\\] \\[H_1: \\text{algún par de medias es distinta}\\] Estos análisis podemos llevarlos a cabo con la función aov Ejemplo Supongamos que queremos averiguar si la edad de la primera relación sexual se asocia con si la mujer es fumadora, no fumadora o ex-fumadora (variable fumar). En este caso, contestaríamos a la pregunta mediante mod &lt;- aov(edad1sex ~ fumar, data=multicentric) summary(mod) Df Sum Sq Mean Sq F value Pr(&gt;F) fumar 2 688 343.9 15.51 2e-07 *** Residuals 2886 64004 22.2 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 21 observations deleted due to missingness Puesto que el p-valor asociado a esta prueba es &lt;0.05, concluiríamos que nuestros datos aportan evidencias para rechazar la hipótesis nula. Por lo tanto, la media de la primera relación sexual es distinta para alguno de los grupos que estamos comparando. Ahora tendríamos que decir entre qué grupos hay diferencias, y para ello, usaríamos lo que se conoce como post-hoc tests. Existen numerosos tests en la literatura para hacer estas comparaciones a posteriori cuando hemos rechazado la hipótesis nula en un ANOVA. Nosotros usaremos TukeyHSD que es sencilla de usar, es uno de los métodos más robustos y no requiere ninguna otra libería. Basta con ejecutar la función sobre el objeto anterior que contiene el ANOVA TukeyHSD(mod) Tukey multiple comparisons of means 95% family-wise confidence level Fit: aov(formula = edad1sex ~ fumar, data = multicentric) $fumar diff lwr upr p adj fumador-ex-fumador -0.381524 -1.3665451 0.603497 0.6351209 no fumador-ex-fumador 1.046651 0.2732668 1.820036 0.0043414 no fumador-fumador 1.428176 0.7391876 2.117163 0.0000037 Este test nos diría que hay diferencias entre los grupos de no fumadoras y las exfumadoras y fumadoras. Notemos que el resultado de los análisis muestra p adj que indica que es un p-valor ajustado ya que estamos haciendo muchas comparaciones estadísticas (tres) con los mismos datos y necesitamos tener esto en cuenta para tener un valor de significación global del 5%. 5.6 Prueba de hipótesis para la igualdad de proporciones \\(p_A = p_B\\) Para realizar pruebas de hipótesis para comparar dos proporciones se usa la función chisq.test. Ejemplo Supongamos que queremos investigar si dar positivo en el test del virus de papiloma humano (variable vph) es un factor de riesgo para desarrollar cáncer cervical. La hipótesis que se planteraria sería: \\[H_0: p_{\\text{controles}} = p_{\\text{casos}}\\] \\[H_0: p_{\\text{controles}} \\neq p_{\\text{casos}}\\] En este caso, variable de interés es categórica (binaria) y la queremos comparar entre dos grupos. En ese caso necesitamos usar un test de Chi-cuadrado que se calcula a partir de la tabla de contingencia que recordemos del capítulo anterior que se puede obtener de la siguiente forma con la librería summarytools: library(summarytools) ctable(multicentric$vph, multicentric$status, useNA=&quot;no&quot;, prop=&quot;c&quot;) Cross-Tabulation, Column Proportions vph * status Data Frame: multicentric ---------- -------- --------------- --------------- --------------- status Caso Control Total vph negativo 81 ( 6.4%) 996 ( 85.6%) 1077 ( 44.2%) positivo 1190 ( 93.6%) 168 ( 14.4%) 1358 ( 55.8%) Total 1271 (100.0%) 1164 (100.0%) 2435 (100.0%) ---------- -------- --------------- --------------- --------------- Vemos que la proporción de casos que dan positivo en la prueba es del 93.6%, mientras que en los controles es de tan sólo el 14.4%. Esto parece indicar que ambas variables están relacionadas, o en otras palabras, que dar positivo por este virus es un factor de riesgo para el cáncer cervical. Pero, como siempre, a estas diferencias le tenemos quedar un valor de significación estadística que podemos obtener de dos formas. Una poniendo el argumento chisq=TRUE en la función anterior ctable(multicentric$vph, multicentric$status, useNA=&quot;no&quot;, prop=&quot;c&quot;, chisq=TRUE) Cross-Tabulation, Column Proportions vph * status Data Frame: multicentric ---------- -------- --------------- --------------- --------------- status Caso Control Total vph negativo 81 ( 6.4%) 996 ( 85.6%) 1077 ( 44.2%) positivo 1190 ( 93.6%) 168 ( 14.4%) 1358 ( 55.8%) Total 1271 (100.0%) 1164 (100.0%) 2435 (100.0%) ---------- -------- --------------- --------------- --------------- ---------------------------- Chi.squared df p.value ------------- ---- --------- 1542 1 0 ---------------------------- y otra, usando la función chisq.test, pero que no devuelve la tabla ni los porcentajes. chisq.test(multicentric$vph, multicentric$status) Pearson&#39;s Chi-squared test with Yates&#39; continuity correction data: multicentric$vph and multicentric$status X-squared = 1541.6, df = 1, p-value &lt; 2.2e-16 Vemos que en ambos casos obtenemos el mismo resultado, que no es otro que tenemos suficientes evidencias en nuestros datos para rechazar la hipótesis de igualdad de proporciones ya que el p-valor es menor que 0.05, por lo que la proporción de infectadas en casos es distinta que en controles (mayor) o lo que es lo mismo, que esta variable es un factor de riesgo para el cáncer cervical. 5.7 Pruebas no paramétricas En el ejemplo de la variable edad de la primera relación sexual, hemos visto que no sigue una distribución normal, por lo que los métodos anteriormente descrito no serían válidos. En realidad, no es que no lo sean, si no que no son los más potentes para encontrar diferencias cuando realmente las hay. Esto iría en contra nuestra como investigadores. Es por ello que, en estos casos, se recomienda usar tests no paramétricos que no suponen ninguna distribución para los datos. La alternativa al t-test es el test de Mann–Whitney–Wilcoxon, también conocido como test de la suma de rangos de Wilcoxon. Es un test no paramétrico que contrasta si dos muestras proceden de poblaciones equidistribuidas. Como nuestra variable edad1sex no seguía una distribución normal, lo ideal hubiera sido utilizar un test no paramétrico. Para la prueba \\[H_0: \\mu =18\\] usaríamos wilcox.test(multicentric$edad1sex, mu=18) Wilcoxon signed rank test with continuity correction data: multicentric$edad1sex V = 2240843, p-value &lt; 2.2e-16 alternative hypothesis: true location is not equal to 18 y para la prueba \\[H_0: \\mu_\\text{controles} = \\mu_\\text{casos}\\] sería wilcox.test(edad1sex~status, data=multicentric) Wilcoxon rank sum test with continuity correction data: edad1sex by status W = 760404, p-value &lt; 2.2e-16 alternative hypothesis: true location shift is not equal to 0 Y en ambos casos obtendríamos la misma conclusión que con un test paramétrico. Para el caso de un test de ANOVA, que también requiere normalidad, deberíamos usar el test de Kruskall-Wallis que se calcula así: kruskal.test(edad1sex~fumar, data=multicentric) Kruskal-Wallis rank sum test data: edad1sex by fumar Kruskal-Wallis chi-squared = 31.373, df = 2, p-value = 1.54e-07 Al igual que con ANOVA, debemos realizar tests a posteriori para ver entre qué grupos hay differencias utilizando un métodos no paramétrico. Esto lo podemos hacer con el test de Nemenyi que está implementado en la librería DescTools que primero debemos instalar con la instrucción install.packages(\"DescTools\"). Al igual que en el caso del ANOVA, usaremos el método propuesto por Tukey. La instrucción es la siguiente. Notemos que la variable grupal (argumento g) debe ser factor, por eso usamos la función as.factor(): library(DescTools) pvals &lt;- NemenyiTest(x = multicentric$edad1sex, g = as.factor(multicentric$fumar), dist=&quot;tukey&quot;) pvals Nemenyi&#39;s test of multiple comparisons for independent samples (tukey) mean.rank.diff pval fumador-ex-fumador -70.27367 0.6121 no fumador-ex-fumador 184.23356 0.0046 ** no fumador-fumador 254.50724 3e-06 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 De nuevo obtendríamos un valor similar al test paramétrico. Esto ocurre porque tenemos una base de datos con muchos casos, y los test paramétricos suelen funcionar bien. IMPORANTE: Los test no paramétricos muestras su mejor potencia cuando las bases de datos son pequeñas. Finalmente, el test de Chi-cuadrado que hemos calculado para testar \\[H_0: p_{\\text{controles}} = p_{\\text{casos}}\\] también tiene su versión no paramétrica en el test de Fisher. Este test es necesario no sólo cuando hay poco tamaño muestral, si no que también cuando hay pocos casos en algunas de las celdas de la tabla de contingencia. Este test podríamos calcularlo con esta función: fisher.test(multicentric$vph, multicentric$status) Fisher&#39;s Exact Test for Count Data data: multicentric$vph and multicentric$status p-value &lt; 2.2e-16 alternative hypothesis: true odds ratio is not equal to 1 95 percent confidence interval: 0.008625214 0.015318378 sample estimates: odds ratio 0.01152201 que al igual que en los casos anteriores, llegamos a la misma conclusión que con un test paramétrico. "],
["modelos-de-regresión.html", "6 Modelos de regresión 6.1 Regresión lineal 6.2 Regresión logística 6.3 Creación de modelos", " 6 Modelos de regresión ¿Qué son los modelos? Los modelos simplifican la realidad con fines de comprensión o predicción. Si bien pueden ser herramientas poderosas, debemos tener en cuenta que, después de todo, no son la realidad. En consecuencia, como se dice que dijo el estadístico George Box, “Todos los modelos son incorrectos, pero algunos son útiles”. En términos generales, el modelado estadístico tiene estos dos objetivos a veces divergentes: Descripción: usar un modelo para describir la relación entre una variable de resultado de interés y una o más variables predictoras. Predicción: uso de un modelo para predecir instancias desconocidas de la variable de resultado de manera que se minimice el error predictivo fuera de la muestra. En el modelado, es posible centrarse en la descripción e ignorar la predicción, y viceversa. Por ejemplo, muchos algoritmos de aprendizaje automático son cajas negras: crean modelos que hacen un buen trabajo de predicción, pero son difíciles, si no imposibles, de interpretar y, en consecuencia, a menudo no nos ayudan a comprender las relaciones entre variables. La regresión lineal puede no ser la técnica más sofisticada, pero si se usa correctamente, su precisión predictiva compara bien con otros algoritmos más avanzados que veremos en este curso. Además, ofrece información descriptiva, en forma de coeficientes para cada variable, que son de gran utilida. La regresión lineal y logística hacen un buen trabajo con tanto descripción como predicción. En este capítulo aprenderemos los usos de ambos tipos de regresión 6.1 Regresión lineal Esta sección presenta la regresión lineal, el método de regresión paramétrica que usamos cuando la variable de resultado o respuesta es continua. Cuando el resultado es binario, utilizamos la regresión logística, tema que veremos en la sección siguiente. Comencemos por presentar brevemente el modelo lineal junto con algunos de los conceptos y terminología que usaremos a lo largo del curso. Un modelo lineal es paramétrico porque asumimos que la relación entre dos variables es lineal y puede ser definida por los parámetros de una recta (el intercept y la pendiente). Comenzaremos considerando un modelo lineal simple. En la siguiente figura podemos observar cómo existe una relación lineal entre la dosis de chocolate consumida y el nivel de felicidad reportado por una muestra de individuos seleccionados al azar en una población de Barcelona. Los puntos negros muestran los datos observados para cada individuo y los blancos representan a la felicidad que tendría cada individuo según la dosis de chocolate que reporta tomar. Regresión lineal simple 6.1.1 Modelo lineal simple Un modelo lineal simple tiene un resultado (outcome, variable predictiva - en nuestro ejemplo la felicidad), \\(y\\), y un predictor, \\(x\\) (el consumo de chocolate en nuestro ejemplo). Está definido por la siguiente ecuación. \\[ y_i = \\beta_0 + \\beta_1x_i + \\epsilon_i, \\] donde \\(i = 1, \\ldots, n.\\) El subíndice en esta ecuación, \\(i\\), indexa las observaciones \\(n\\) en el conjunto de datos. (Pensemos en \\(i\\) como un número de fila que corresponde a los datos de un individuo). La ecuación se puede leer de la siguiente manera: el valor de la \\(i\\)-ésima variable resultado, \\(y_i\\), está definido por una intercept, \\(\\beta_0\\), más una pendiente, \\(\\beta_1\\), multiplicada por la variable predictora \\(i\\)-ésima, \\(x_i\\). Estos elementos definen la parte sistemática o determinista del modelo. Sin embargo, debido a que el mundo es incierto y contiene aleatoriedad, sabemos que el modelo será incorrecto (estará sujeto a error). Para describir completamente los datos, necesitamos un término de error, \\(\\epsilon_i\\), que también está indexado por fila. El término de error es la parte estocástica o aleatoria del modelo. \\(\\epsilon_i\\) mide la distancia entre los valores ajustados o esperados del modelo — calculados a partir de la parte determinista del modelo — y los valores reales. Los errores en un modelo lineal, también conocidos como residuales del modelo, son la parte de los datos que permanece sin explicar por la parte determinista del modelo. Uno de los supuestos clave de un modelo lineal es que los residuos se distribuyen normalmente con media = 0 y varianza = \\(\\sigma^2\\), que denotamos, en notación matricial, como \\(N (0, \\sigma ^ 2)\\). 6.1.2 Regresión lineal multivariante Podemos agregar predictores adicionales, \\(p\\), a un modelo lineal simple, convirtiéndolo en un modelo lineal multivariante, que definimos de la siguiente manera: \\[ y_i = \\beta_0 + \\beta_1 x_ {i1} + \\cdots + \\beta_p x_ {ip} + \\varepsilon_i, \\] donde \\(i = 1, \\ldots, n\\) y \\(p = 1, \\ldots, p.\\) En esta ecuación \\(y_i\\) es nuevamente la variable resultado \\(i\\)-ésima, \\(\\beta_0\\) es la intercept, \\(\\beta_1\\) es el coeficiente de la primera variable predictora, \\(x_{1}\\), \\(\\beta_p\\) es el coeficiente de la variable predictora \\(p\\)-ésima, \\(x_{p}\\), y \\(\\epsilon_i\\) representa la parte estocástica del modelo, los residuos, indexados por fila. La parte determinista del modelo se puede resumir como \\(X \\beta\\), una matriz \\(p\\) x \\(n\\), que llamaremos el “predictor lineal”. 6.1.3 Ajuste de un modelo lineal Para ajustar un modelo lineal usamos la función lm(). (La función glm() también se ajusta a un modelo lineal por defecto, definido por family = gaussian. Usaremosglm() para ajustar una regresión logística, confamily = binomial). Por ejemplo, usemos el conjunto de datos mtcars que está por defecto en R, para averiguar si el consumo de combustible (mpg) está correlacionado con el peso del coche (wt). En R deberíamos ejecutar: data(mtcars) simple_model &lt;- lm(mpg ~ wt, data = mtcars) summary(simple_model) Call: lm(formula = mpg ~ wt, data = mtcars) Residuals: Min 1Q Median 3Q Max -4.5432 -2.3647 -0.1252 1.4096 6.8727 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 37.2851 1.8776 19.858 &lt; 2e-16 *** wt -5.3445 0.5591 -9.559 1.29e-10 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 3.046 on 30 degrees of freedom Multiple R-squared: 0.7528, Adjusted R-squared: 0.7446 F-statistic: 91.38 on 1 and 30 DF, p-value: 1.294e-10 La ecuación del modelo es: \\(\\widehat {mpg} = 37.285 - 5.344wt\\). Notemos que el ajuste del modelo viene dado por el Adjusted R-squared (versión ajustada del R-cuadrado, \\(R^2\\), que tiene en cuenta el número de variables y que nos servirá para comparar modelos con distinto número de variables). En este caso el modelo tiene un \\(R^2\\) de 0.74, lo que nos indica que la variable wt (ó wt_centered) explica un 74% de la variabilidad de mpg. El modelo se puede utilizar para calcular valores ajustados para coches individuales en el conjunto de datos. Por ejemplo, el valor ajustado para el Mazda RX4, \\(\\widehat {mpg_1}\\), se puede derivar de la ecuación del modelo, \\(\\beta_0 + \\beta_1 x_ {i1}\\): 37.29 - 5.34 x 2.62 = 23.28. (El valor real del Mazda RX4, calculado a partir del modelo, sería: 37.29 - 5.34 x 2.62 + 2.28 = 21). El modelo también se puede utilizar para la predicción. ¿Cuál sería el mpg para un coche que pesa 5000 libras? Según el modelo: 37,29 - 5,34 x 5 = 10.56. 6.1.4 Interpretación de coeficientes ¿Cómo interpretamos la salida de la función lm()? Comencemos con el modelo simple de mpg. intercept: 37.29 representa el valor predicho de mpg cuando wt es 0. Dado que wt no puede ser igual a 0. El intercept no es interpretable en este modelo. Para hacerlo interpretable, necesitamos centrar la variable wt en 0, lo que podemos hacer fácilmente restando la media de wt de cada observación (\\(x_ {centrado} = x - \\ bar {x}\\)). Esta es una transformación lineal que cambiará la escala del predictor y, por lo tanto, \\(\\beta_0\\) también, pero no el ajuste del modelo: \\(\\beta_1\\) permanecerá igual (-5,34) al igual que RSS (278,32). Después de la transformación, el peso promedio del coche es 0 y el intercept representa las millas por galón pronosticadas para coches de peso promedio. mtcars &lt;- mutate(mtcars, wt_centered = wt - mean(wt)) simple_model &lt;- lm(mpg ~ wt_centered, data = mtcars) summary(simple_model) Call: lm(formula = mpg ~ wt_centered, data = mtcars) Residuals: Min 1Q Median 3Q Max -4.5432 -2.3647 -0.1252 1.4096 6.8727 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 20.0906 0.5384 37.313 &lt; 2e-16 *** wt_centered -5.3445 0.5591 -9.559 1.29e-10 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 3.046 on 30 degrees of freedom Multiple R-squared: 0.7528, Adjusted R-squared: 0.7446 F-statistic: 91.38 on 1 and 30 DF, p-value: 1.294e-10 Ahora el intercept, 20.09, es significativa y representa el valor predicho de mpg cuando wt_centered es 0 — es decir, cuando wt es promedio. Hay dos formas de interpretar los coeficientes de las variables en un modelo lineal: Contrafactual: el coeficiente representa el cambio predicho en el resultado asociado con un aumento de 1 unidad en el predictor, mientras se mantienen constantes los demás predictores (en el caso multivariable). Predictivo: el coeficiente representa la diferencia pronosticada en el resultado entre dos grupos que difieren en 1 unidad en el predictor, mientras se mantienen constantes los otros predictores. Normalmente los coeficientes del modelo se suelen interpretar de acuerdo con el paradigma contrafáctico. Por lo tanto, wt_centered: -5.34 representa el cambio previsto en el resultado, mpg, asociado con un aumento de 1 unidad en wt_centered. Agreguemos un segundo predictor al modelo, una versión binaria de caballos de fuerza (hp_bin), que definiremos como 0 para valores de hp que están por debajo del promedio y 1 para valores mayores o iguales que el promedio. mtcars &lt;- mutate(mtcars, hp_bin = ifelse(hp &lt; mean(hp), 0, 1)) multivariable_model &lt;- lm(mpg ~ wt_centered + hp_bin , data = mtcars) summary(multivariable_model) Call: lm(formula = mpg ~ wt_centered + hp_bin, data = mtcars) Residuals: Min 1Q Median 3Q Max -3.2845 -2.2699 -0.3736 1.3854 6.5109 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 21.6489 0.8132 26.622 &lt; 2e-16 *** wt_centered -4.1683 0.7096 -5.875 2.25e-06 *** hp_bin -3.3243 1.3693 -2.428 0.0216 * --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 2.824 on 29 degrees of freedom Multiple R-squared: 0.7946, Adjusted R-squared: 0.7804 F-statistic: 56.09 on 2 and 29 DF, p-value: 1.08e-10 Este modelo multivariante es una mejora con respecto al modelo simple ya que tiene un \\(R^2\\) ajustado de 0.78 que es mayor que el del modelo simple. intercept: 21,65 representa el mpg predicho cuando los predictores continuos o binarios son iguales a 0 o (no aplicable en este caso) cuando las variables de los factores están en su nivel de referencia. El intercept es el mpg pronosticado por el modelo para autos de peso promedio que tienen caballos de fuerza por debajo del promedio. wt_centered: -4,17 representa el cambio previsto en mpg asociado con un aumento de 1 unidad en wt_centered (digamos, de 1 a 2) mientras se mantiene constante el otro predictor, hp_bin. Los coeficientes de regresión multivariable capturan cómo el resultado varía de manera única con un predictor dado, después de tener en cuenta los efectos de todos los demás predictores. En la práctica, esto significa que el coeficiente que describe la relación entre mpg y wt_centrado se ha promediado en los niveles hp_bin, por lo que es igual en cada nivel de hp_bin. hp_bin: -3.32 representa el cambio previsto en mpg asociado con un aumento de 1 unidad en hp_bin (de 0 a 1) mientras se mantiene constante el otro predictor, wt_centered. 6.1.5 Inferencia en el contexto de regresión Además de las estimaciones de coeficientes para cada variable predictora (incluido el intercept), la salida de lm () (usando summary ()) contiene la siguiente información: “Error estándar”, “valor t” y “Pr (&gt; | t |)” (el valor p). Repasemos estos conceptos. Recordemos que la inferencia estadística nos permite estimar las características de la población a partir de las propiedades de una muestra. Por lo general, queremos saber si una diferencia o una relación que observamos en una muestra es verdadera en la población — es “estadísticamente significativa” — o es probable que se deba al azar. En el contexto de la regresión, queremos saber específicamente si la pendiente de la recta de regresión, \\(\\beta\\), que resume la relación de una variable con el resultado es diferente de 0. ¿Existe una relación positiva o negativa? En el paradigma frecuentista, respondemos a esta pregunta utilizando pruebas estadísticas basadas en test de hipótesis. De otros cursos sabemos que una prueba de hipótesis se basa en plantear una “hipótesis nula”, \\(H_0\\). En la regresión, \\(H_0\\) corresponde a que la pendiente de la recta de regresión, \\(\\beta\\), es 0. Una pendiente de 0 significa que un predictor no tiene efecto o no tiene relación con el resultado. R calcula automáticamente una prueba de hipótesis para \\(\\beta\\) usando el estadístico t, definido como: \\[ t = \\frac {\\beta - 0} {SE (\\beta)} \\] El estadístico \\(t\\) para una muestra sigue la distribución \\(t\\) de Student con n - 2 grados de libertad. Para la regresión lineal multivariante, el estadístico \\(t\\)sigue la distribución \\(t\\) de Student con $n - k - 1 $ grados de libertad, donde \\(k\\) representa el número de predictores en el modelo. Se utiliza la distribución \\(t\\) porque es más conservadora que una distribución normal cuando \\(n\\) es pequeño ya que en ese caso no podemos asumir el teorema central del límite que nos permitiría determinar que la distribución del estadístico sigue una distribución normal. La distribución \\(t\\) de Student tiene una cola más pesada pero converge a la normal cuando \\(n\\) aumenta (por encima de aproximadamente \\(n\\)= 30). En nuestro ejemplo podemos ver que el p-valor asociado tanto a la variable wt_centered y hp_bin son &lt;0.05, por lo que podríamos concluir que ambas variables son estadísticamente significativas y son necesarias incluirlas en el modelo para explicar el consumo del coche (variable mpg) 6.1.6 Asunciones de un modelo de regresión Los resultados de la regresión solo son precisos si se dan un conjunto de supuestos (en orden de importancia):1 Validez de los datos para responder a la pregunta de investigación. Linealidad de la relación entre el resultado y las variables predictoras. Independencia de los errores (en particular, sin correlación entre errores consecutivos como en el caso de los datos de series de tiempo). Varianza igual de errores (homocedasticidad). Normalidad de errores. La mayoría de estos problemas no son fatales y se pueden solucionar mejorando el modelo, seleccionando variables diferentes o adicionales o utilizando una distribución de modelización diferente (los conocidos como modelos lineales generalizados o GLMs). Los gráficos de residuos son la mejor herramienta para evaluar si se han cumplido los supuestos del modelo. No entraremos demasiado en detalle en todas las pruebas que hay para comprabar estas asunciones, pero mediante el siguiente gráfico podemos determinar si podemos usar nuestro modelo o no para realizar predicciones par(mfrow=c(2,2)) plot(multivariable_model) La instrucción par(mfrow=c(2,2)) es necesaria para que obtengamos un panel con los cuatro gráficos que devuelve la función plot [Veremos este concepto más en detalle cuando hablemos de cómo realizar gráficos con R]. En el gráfico podemos observar como este modelo tiene problema con los residuos ya que el gráfico de QQ-plot nos indicaría que hay tres observaciones (17, 18 y 20) que son valores no esperados en la cola de una distribución normal. Esto coincide con el gráfico de los residuos contra los valores predichos donde estas observaciones tiene un valor de residuo por encima de 2 que se consideraría el límite superior de normalidad. Sin embaro estos puntos no se pueden considerar como puntos influyentes según el gráfico de residuos contra Leverage. Estos resultados sugerirían re-estimar el modelo haciendo una transformación de la variable respuesta (generalmente el logaritmo) que garantice la linealidad del modelo y/o la normalidad de los residuos. 6.2 Regresión logística Hasta ahora, nuestra variable de resultado era continua. Pero si la variable de resultado es binaria (0/1, “No”/“Sí”). La regresión logística se introduce en el contexto de la epidemiología como un modelo de regresión que extiende el modelo lineal cuando nuestra variable respuesta es binaria. Desafortunadamente, debemos afrontar nuevas complicaciones cuando trabajamos con regresión logística, lo que hace que estos modelos sean inherentemente más difíciles de interpretar que los modelos lineales. Las complicaciones surgen del hecho de que con la regresión logística modelamos la probabilidad de que \\(y\\) = 1, y la probabilidad siempre se escala entre 0 y 1. Pero el predictor lineal, \\(X \\beta\\), oscila entre \\(\\pm \\infty\\) (donde \\(X\\) representa un predictor del modelo). Esta diferencia de escala requiere transformar la variable de resultado, lo cual se logra con la función logit: \\[ \\text{logit}(x) = \\text{log}\\left( \\frac{x}{1-x} \\right) \\] La función logit asigna el rango del resultado (0,1) al rango del predictor lineal \\((-\\infty, +\\infty)\\). El resultado transformado, \\(\\text{logit} (x)\\), se expresa en logaritmos de probabilidades (\\(\\frac{x}{1-x}\\)) se conoce como probabilidades del resultado - razón de odds en inglés - momios en castellano). Así que el modelo también se puede escribir como: \\[\\text{Pr}(y_i = 1) = p_i\\] \\[\\text{logit}(p_i) = \\alpha + X_1\\beta_1 + X_2\\beta_2 + \\ldots + X_k\\beta_k\\] Las probabilidades logarítmicas (e.g. el log-odds) no tienen interpretación (que no sea el signo y la magnitud) y deben transformarse nuevamente en cantidades interpretables, ya sea en probabilidades, usando el logit inverso, o en razones de probabilidades, mediante el uso de la función exponencial. Dado que este no es un curso de estadística, asumimos que el estudiante está familiarizado con este tipo de regresión. No obstante, usaremos un ejemplo que ayude a la interpretación de resultados para aquellos alumnos que desconozca o no recuerden bien esta metodología. 6.2.1 Interpretación de los coeficientes Mientras que en regresión lineal \\(\\beta_1\\) se corresponde con el cambio promedio en \\(Y\\) asociado a un incremento de una unidad en \\(X\\), en regresión logística \\(\\beta_1\\) es el valor que indica cuanto cambia el logaritmo de odds cuando \\(X\\) se incrementa en una unidad, o equivalentemente, multiplica los odds por \\(e^{\\beta_1}\\) (donde \\(e\\) es la función exponencial). La cantidad con la que \\(p_i\\) cambia debido a un cambio en \\(X\\) dependerá del valor actual de \\(X\\), pero independientemente de ello, si \\(\\beta_1\\) es positivo, entonces aumentar \\(X\\) provocará un aumento de p(X). El “intercept” \\(\\beta_0\\) corresponde con el resultado predicho para el nivel de referencia. Los parámetros del modelo pueden estimarse con la función glm (modelo lineal generalizado) indicando que la familia que estamos modelando es la binomial. Esto es importante, ya que si no indicamos nada, esta función glm realizará una estimación de los parámetros asumento que nuestra variable resultado (0/1) es continua (regresión lineal). Veamos como estimar un modelo con nuestros datos del estudio multicéntrico para cáncer cervical. Este es un estudio de casos y controles que se debe analizar mediante regresión logística ya que nuestra variable resultado, tener cáncer, es binaria (Control/Caso). Recordemos cómo cargar los datos en R multicentric &lt;- read.delim(&quot;datos/multicentric.txt&quot;) Antes de empezar a realizar análisis debemos asegurarnos que nuestra variable binaria está codificada 0/1, o que almenos tiene las categorías en el orden que nos asegure que estamos modelando la probabilidad del evento que nos interesa, que en este caso es ser caso (tener cáncer). Podemos verlo haciendo una tabla table(multicentric$status) Caso Control 1489 1421 Vemos que la primera categoría es Caso (ya que se ordena alfanuméricamente) por lo que si estimáramos un modelo de regresión logística unsando esta variable como variable dependiente, los coeficientes del modelo nos estarían cuantificando cuál es el efecto de ser control respecto a caso. Es por ello que debemos recodificar nuestra variable y es aconsejable tener dicha información como 0/1. Recodermos que esta recodificación la podemos hacer de la siguiente forma tal y como vimos en la clase de manejo de datos multicentric &lt;- mutate(multicentric, casocon = recode(status, &quot;Caso&quot; = 1, &quot;Control&quot; = 0)) Ahora nuestra variable dependiente será casocon. Supongamos que queremos ver si la edad de la primera relación sexual es un factor asociado a tener cáncer cervival. El modelo sería modelo_simple &lt;- glm(casocon ~ edad1sex, data=multicentric, family=binomial) summary(modelo_simple) Call: glm(formula = casocon ~ edad1sex, family = binomial, data = multicentric) Deviance Residuals: Min 1Q Median 3Q Max -1.8585 -1.1882 0.8876 1.0830 2.5406 Coefficients: Estimate Std. Error z value Pr(&gt;|z|) (Intercept) 2.033107 0.176122 11.54 &lt;2e-16 *** edad1sex -0.100383 0.008782 -11.43 &lt;2e-16 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 (Dispersion parameter for binomial family taken to be 1) Null deviance: 4002.6 on 2888 degrees of freedom Residual deviance: 3857.5 on 2887 degrees of freedom (21 observations deleted due to missingness) AIC: 3861.5 Number of Fisher Scoring iterations: 4 De la misma forma que para el modelo lineal tenemos un test para saber si esta variable está asociada con la variable dependiente, en la regresión logística también podemos calular un p-valor para determinar si el coeficiente es distinto de 0 o no. En este caso, el p-valor es &lt;0.05 (columna Pr(&gt;|z|)) por lo que podríamos concluir que la edad de la primera relación sexual se asocia con la probabilidad de tener cáncer cervical. En particular, el riesgo de tener cáncer cervical desciende un 10% (exp(-0.1)=0.90) por cada año que se retrasa la primera relación sexual. NOTA: debería hablarse de razón de odds (OR) y no de riesgo, pero cuando la incidencia del evento es pequeña la OR puede interpretarse como un riesgo relativo). Ahora podemos añadir otra variable y hacer un modelo multivariante como para el caso de la regresión lineal. Introduzcamos en el modelo la variable infección por papiloma virus (variable vph). En este caso el modelo sería: modelo_multivariable &lt;- glm(casocon ~ edad1sex + vph, data=multicentric, family=binomial) summary(modelo_multivariable) Call: glm(formula = casocon ~ edad1sex + vph, family = binomial, data = multicentric) Deviance Residuals: Min 1Q Median 3Q Max -2.2560 -0.4014 0.4593 0.4995 2.6573 Coefficients: Estimate Std. Error z value Pr(&gt;|z|) (Intercept) -1.63312 0.30665 -5.326 1.01e-07 *** edad1sex -0.04447 0.01417 -3.138 0.0017 ** vphpositivo 4.45194 0.14433 30.845 &lt; 2e-16 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 (Dispersion parameter for binomial family taken to be 1) Null deviance: 3355.2 on 2423 degrees of freedom Residual deviance: 1556.8 on 2421 degrees of freedom (486 observations deleted due to missingness) AIC: 1562.8 Number of Fisher Scoring iterations: 5 En este caso, ambas variables son estadísticamente signifcativas porque el p-valor asociado es &lt;0.05 en los dos casos. Ahora la pregunta es. ¿Cuál de estos dos modelos es mejor? Para esta pregunta no usamos el \\(R^2\\) si no que usamos el criterio de información de Akaike (AIC) \\[\\mathrm {AIC} = - 2 \\ln(L) + 2k\\] que nos cuatifica la verosimilitud (\\(L\\)) de cada modelo penalizando por el número de varibles (\\(k\\)) ya que la introducción de variables mejora el ajuste por el mero hecho de considerar más información. El AIC menor indicaría mejor modelo. Esto lo podemos hacer con R mediante: AIC(modelo_simple) [1] 3861.472 AIC(modelo_multivariable) [1] 1562.839 Podemos ver que el modelo con dos variables ajusta mucho mejor a los datos. Ahora bien ¿qué ocurriría si introducimos más variables? ¿Cómo seleccionamos aquellas variables más relevantes? Estas preguntas tendrán respuesta en la siguiente sección 6.3 Creación de modelos ¿Cómo sabemos qué variables (independientes) deben incluirse en un modelo? La respuesta sencilla es: a menudo no lo sabemos. Aquí hay algunas reglas generales cuando se piensa en la selección de variables: Piensa en los datos. ¿Qué variables tiene sentido incluir dada la situación? ¿Alguna literatura publicada ofrece orientación? Si estamos en modo descriptivo, es posible que solo nos interesen determinadas variables y utilicemos las demás como controles. Si estamos en modo predictivo, incluimos todas las variables que, por razones aditivas, podrían ser importantes para predecir el resultado. Sin embargo, esta es una guía muy general, ya que diferentes contextos exigen diferentes enfoques para el ajuste del modelo. Incluir términos cuadráticos si hay evidencia de gráficos bivariados de una relación no lineal entre predictor y resultado. En general, no incluimos términos polinomiales con grados superiores a 2. Para hacerlo, se corre el riesgo de sobreajuste (término del que hablaremos más tarde). Buscar posibles interacciones entre variables con los efectos principales más grandes. En general, no incluimos interacciones de orden superior (mayores que 2) a menos que tengamos una razón lógica y podamos explicarla. También hay que tener en cuenta que las interacciones son bastante difíciles de explicar. Considerar combinar predictores separados en un solo predictor — un “puntaje total” — obtenido al sumarlos o promediarlos. Simplicidad. Los modelos sencillos son casi siempre mejores — son más interpretables y tienden a tener menor variación (principio de parsimonia). 6.3.1 Selección paso a paso (stepwise) La técnica tradicional en estadística para seleccionar variables es selección paso a paso (o stepwise en inglés). Con selección hacia adelante comenzamos con un modelo nulo (solo contiene el intercept) y agregamos una variable a la vez. Si la variable agregada mejora el modelo, la mantenemos y agregamos otra. Continuamos hasta que se hayan probado todas las variables como podemos ver en la siguiente figura: Selección hacia adelante Con selección hacia atrás comenzamos con un modelo completo (todos los términos disponibles) y eliminamos variables en serie (una a una). Si el modelo es mejor después de eliminar una variable, lo dejamos fuera. Continuamos hasta que se hayan probado todas las variables como podemos ver en la siguiente figura: Selección hacia atrás Selección hacia adelante seguida de selección hacia atrás (saltos). Consiste en ir realizando en cada paso una selección hacia adelante o hacia atrás en función del mejor paso que podamos hacer. Desafortunadamente, estos procedimientos de ajuste manual son defectuosos. Dependen del orden en el que se agregan o excluyen las variables y, a menudo, no seleccionarán el mejor modelo. Además, por ejemplo, supongamos que tenemos una base de datos con \\(k\\) = 13 variables predictoras, lo que significa que hay \\(2^k\\) o 8192 modelos posibles que podríamos ajustar y eso sin tener encuenta la posible introducción de interacciones o términos polinómicos. Este es un espacio extremadamente grande para buscar el mejor modelo, y la búsqueda es computacionalmente costosa y requiere mucho tiempo. Realizar tal búsqueda manualmente sería prácticamente imposible. Se han desarrollado algoritmos para buscar en el espacio de modelos de manera eficiente el modelo óptimo. Sin embargo, desde el principio conviene tener cuidado con la selección automática de variables. La elección de variables no debe ser un proceso mecánico. Debemos, en cambio, buscar comprender el proceso de generación de datos. De hecho, el mayor beneficio de la selección manual por pasos consiste menos en producir un buen modelo que en la comprensión obtenida al ajustar muchos modelos y ver, mediante prueba y error, qué predictores son más reactivos con el resultado. Especialmente cuando se trata de descripción, los algoritmos de selección automática de variables son solo herramientas para explorar sus datos y pensar en modelos. La función step () en R base automatiza la selección de variables paso a paso usando AIC. Primero tenemos que definir nuestro modelo completo, es decir, el modelo con las variables que queremos usar para la selección de variables. En nuestro caso supongamos que queremos ver qué variables son importantes entre, infección por papiloma virus, edad de la primera relación sexual, ser fumador, nivel educativo, uso de contraceptivos orales y el pais de origen. El modelo sería entonces mod &lt;- glm(casocon ~ vph + edad1sex + fumar + niveledu + co + pais, data = multicentric, family=&quot;binomial&quot;) Ahora con la función step podemos hacer, por ejemplo, la selección automática por el método backward de la siguiente forma: modF &lt;- step(mod, trace = F, direction = &quot;backward&quot;) summary(modF) Call: glm(formula = casocon ~ vph + edad1sex + fumar + niveledu + pais, family = &quot;binomial&quot;, data = multicentric) Deviance Residuals: Min 1Q Median 3Q Max -2.6353 -0.3658 0.2662 0.4879 3.1635 Coefficients: Estimate Std. Error z value Pr(&gt;|z|) (Intercept) -1.29712 0.44815 -2.894 0.003799 ** vphpositivo 4.64396 0.15804 29.385 &lt; 2e-16 *** edad1sex -0.04765 0.01628 -2.927 0.003426 ** fumarfumador -0.01603 0.35946 -0.045 0.964435 fumarno fumador -0.74681 0.28200 -2.648 0.008090 ** niveleduprimaria -0.36957 0.19984 -1.849 0.064409 . niveledusecundaria -1.03821 0.24651 -4.212 2.53e-05 *** niveleduticnico -1.08495 0.50825 -2.135 0.032788 * niveleduuniversitario -2.12402 0.60953 -3.485 0.000493 *** paisColombia 0.67612 0.31797 2.126 0.033473 * paisEspaia 1.65083 0.32244 5.120 3.06e-07 *** paisFilipinas 1.17099 0.26442 4.428 9.49e-06 *** paisMarruecos -0.13458 0.29181 -0.461 0.644661 paisPeri 0.60008 0.28748 2.087 0.036855 * paisTailandia 0.86177 0.25125 3.430 0.000604 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 (Dispersion parameter for binomial family taken to be 1) Null deviance: 3355.2 on 2423 degrees of freedom Residual deviance: 1474.7 on 2409 degrees of freedom (486 observations deleted due to missingness) AIC: 1504.7 Number of Fisher Scoring iterations: 5 en el objeto modF tenemos el modelo final. Vemos que se han seleccionado todas las variables menos uso de contraceptivos orales que si la inluyéramos en el modelo veríamos que no estadísticamente signifativa. Para los modelos lineales, esta función sirve de la misma forma. Basta con remplazar el modelo glm por lm. De Gelman y Hill (2007). Análisis de datos mediante regresión y modelos jerárquicos / multinivel. Cambridge: Cambridge UP.↩︎ "]
]
